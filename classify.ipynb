{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import pi, matmul,sqrt,dot,array,zeros,cos,sin,pi,arccos\n",
    "from torch.utils.data import DataLoader\n",
    "from func import OR,heatplot,misorientation,mat2plot, match,imgshow,calpoint,L2,L1,ipfread\n",
    "from Class import Exp,Data,Cluster\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,bef,im,target):\n",
    "        self.bef=bef\n",
    "        self.im=im\n",
    "        self.target=target\n",
    "    def __getitem__(self,index):\n",
    "        X=self.bef[index]\n",
    "        Y=self.target[index]\n",
    "        im=self.im[index]\n",
    "        return torch.tensor(X,dtype=torch.float32),torch.tensor(Y,dtype=torch.long),im\n",
    "    def __len__(self):\n",
    "        return len(self.bef)\n",
    "def negsample(corner):\n",
    "    mat=np.zeros([500,500])\n",
    "    for (i,j) in corner:\n",
    "        for k in range(max(0,i-49),min(500,i+50)):\n",
    "            for l in range(max(0,j-49),min(500,j+50)):\n",
    "                mat[k,l]=1\n",
    "    cand = []\n",
    "    for i in range(451):\n",
    "        for j in range(451):\n",
    "            if not mat[i][j]:\n",
    "                cand.append([i,j])\n",
    "    return random.sample(cand,len(corner))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(root=\"data/train/\",feature=[\"orient\",\"MAD\"]):\n",
    "    corner=torch.load(\"data/corner.pkl\")\n",
    "    bef=[]\n",
    "    im=[]\n",
    "    target=[]\n",
    "    h=w=50\n",
    "    for date in os.listdir(root):\n",
    "        path=root+date+\"/before/\"\n",
    "        data=Data(path)\n",
    "        data.data[\"orient\"]=data.data[\"orient\"].reshape(data.h,data.w,-1)\n",
    "        for (i,j) in corner[date]:\n",
    "            im.append(ipfread(path)[i:i+h,j:j+w]/255.)\n",
    "            app=[]\n",
    "            for ele in feature:\n",
    "                if ele==\"orient\":\n",
    "                    app.append(data.data[ele][i:i+h,j:j+w])\n",
    "                else:\n",
    "                    app.append(data.data[ele][i:i+h,j:j+w,np.newaxis])\n",
    "            bef.append(np.concatenate(app,axis=2))\n",
    "            target.append(0)\n",
    "        for (i,j) in negsample(corner[date]):\n",
    "            im.append(ipfread(path)[i:i+h,j:j+w]/255.)\n",
    "            app=[]\n",
    "            for ele in feature:\n",
    "                if ele==\"orient\":\n",
    "                    app.append(data.data[ele][i:i+h,j:j+w])\n",
    "                else:\n",
    "                    app.append(data.data[ele][i:i+h,j:j+w,np.newaxis])\n",
    "            bef.append(np.concatenate(app,axis=2))\n",
    "            target.append(1)\n",
    "        \n",
    "    bef=np.transpose(np.array(bef),(0,3,1,2))\n",
    "    im=np.array(im)\n",
    "    target=np.array(target)\n",
    "    return Dataset(bef,im,target)\n",
    "train=create_dataset(\"data/train/\",feature=[\"orient\",\"BC\",\"BS\"])\n",
    "test=create_dataset(\"data/test/\",feature=[\"orient\",\"BC\",\"BS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN3, self).__init__()\n",
    "        self.batchnorm = nn.BatchNorm2d(in_channel)\n",
    "        self.relu = nn.ReLU() # activation\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2) \n",
    "        self.cnn1 = nn.Conv2d(in_channels=in_channel, out_channels=12, kernel_size=3, stride=1, padding=0) \n",
    "        self.cnn2 = nn.Conv2d(in_channels=12, out_channels=18, kernel_size=3, stride=1, padding=1) \n",
    "        self.cnn3 = nn.Conv2d(in_channels=18, out_channels=24, kernel_size=3, stride=1, padding=0) \n",
    "        self.fc1 = nn.Linear(24 * 5 * 5, 2) \n",
    "        self.softmax = nn.Softmax(1)\n",
    "    def forward(self, x):\n",
    "        # Convolution 1 50\n",
    "        out = self.batchnorm(x)\n",
    "        out = self.cnn1(x) # 48\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out) #24\n",
    "        out = self.cnn2(out) #24\n",
    "        out = self.relu(out) \n",
    "        out = self.maxpool(out) #12\n",
    "        out = self.cnn3(out) #10\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out) #5\n",
    "        out = out.view(out.size(0), -1)\n",
    "        # Linear function (readout)\n",
    "        out = self.fc1(out)\n",
    "        out = self.softmax(out)\n",
    "        return out\n",
    "class CNN5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN5, self).__init__()\n",
    "        self.batchnorm = nn.BatchNorm2d(in_channel)\n",
    "        self.relu = nn.ReLU() # activation\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2) \n",
    "        self.cnn1 = nn.Conv2d(in_channels=in_channel, out_channels=12, kernel_size=3, stride=1, padding=0) \n",
    "        self.cnn2 = nn.Conv2d(in_channels=12, out_channels=18, kernel_size=3, stride=1, padding=0) \n",
    "        self.cnn3 = nn.Conv2d(in_channels=18, out_channels=24, kernel_size=3, stride=1, padding=0) \n",
    "        self.fc1 = nn.Linear(24 * 9 * 9, 2) \n",
    "        self.softmax = nn.Softmax(1)\n",
    "    def forward(self, x):\n",
    "        # Convolution 1 50\n",
    "        out = self.batchnorm(x)\n",
    "        out = self.cnn1(x) # 48\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out) #24\n",
    "        out = self.cnn2(out) #22\n",
    "        out = self.relu(out) \n",
    "        out = self.maxpool(out) #11\n",
    "        out = self.cnn3(out) #9\n",
    "        out = self.relu(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        # Linear function (readout)\n",
    "        out = self.fc1(out)\n",
    "        out = self.softmax(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader= DataLoader(train, batch_size=64, shuffle=True,  num_workers=0, drop_last=True )\n",
    "test_loader= DataLoader(test, batch_size=64, shuffle=True,  num_workers=0,  drop_last=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.4328786134719849\n",
      "acc=  50 / 102\n",
      "1 1.3680508136749268\n",
      "acc=  52 / 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kisaki/anaconda3/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type CNN3. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 1.3709940910339355\n",
      "acc=  55 / 102\n",
      "6 1.348008394241333\n",
      "acc=  61 / 102\n",
      "7 1.3372080326080322\n",
      "acc=  69 / 102\n",
      "10 1.32179856300354\n",
      "acc=  71 / 102\n",
      "16 1.2909302711486816\n",
      "acc=  74 / 102\n",
      "23 1.2593402862548828\n",
      "acc=  77 / 102\n",
      "27 1.235084056854248\n",
      "acc=  78 / 102\n",
      "37 1.1921640634536743\n",
      "acc=  79 / 102\n"
     ]
    }
   ],
   "source": [
    "in_channel=train[0][0].shape[0]\n",
    "model = CNN3()\n",
    "Loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "max_acc = 0\n",
    "epoch = 400\n",
    "for ep in range(epoch):\n",
    "    for batch_ndx, sample in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        X,Y,_= sample\n",
    "        output=model(X)\n",
    "        loss = Loss(output,Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         print(\"train \",ep,loss.item())\n",
    "    model.eval()\n",
    "    cum=0\n",
    "    loss=0\n",
    "    for batch_ndx, sample in enumerate(test_loader):\n",
    "        X,Y,_= sample\n",
    "        output=model(X)\n",
    "        loss+=Loss(output,Y)\n",
    "        predict = torch.max(output, 1)[1]\n",
    "        cum+=np.sum((Y == predict).cpu().numpy())\n",
    "    acc=cum/len(test)\n",
    "    if acc>max_acc:\n",
    "        max_acc=acc\n",
    "        min_loss = loss.item()\n",
    "        print(ep,min_loss)\n",
    "        print(\"acc= \",cum,\"/\",len(test))\n",
    "        torch.save(model,\"model/%s_obcbs_%.3f\"%(type(model).__name__,acc))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m1 = torch.load(\"model/CNN5_0.755\")\n",
    "# m2 = torch.load(\"model/CNN3_0.765\")\n",
    "# m1.eval()\n",
    "# m2.eval()\n",
    "# cum=0\n",
    "# for batch_ndx, sample in enumerate(test_loader):\n",
    "#     X,Y,_= sample\n",
    "#     output=m2(X)+m1(X)\n",
    "#     predict = torch.max(output, 1)[1]\n",
    "#     cum+=np.sum((Y == predict).cpu().numpy())\n",
    "# print(cum/len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load(\"model/0.765\")\n",
    "# corner=torch.load(\"data/corner.pkl\")\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "# index=1\n",
    "# X=test[index][0].unsqueeze(0)\n",
    "# print(test[index][1])\n",
    "\n",
    "# # we would run the model in evaluation mode\n",
    "# model.eval()\n",
    "\n",
    "# # we need to find the gradient with respect to the input image, so we need to call requires_grad_ on it\n",
    "# X.requires_grad_()\n",
    "\n",
    "# '''\n",
    "# forward pass through the model to get the scores, note that VGG-19 model doesn't perform softmax at the end\n",
    "# and we also don't need softmax, we need scores, so that's perfect for us.\n",
    "# '''\n",
    "\n",
    "# scores = model(X)\n",
    "# print(scores)\n",
    "# # Get the index corresponding to the maximum score and the maximum score itself.\n",
    "# score_max_index = scores.argmax()\n",
    "# score_max = scores[0,score_max_index]\n",
    "\n",
    "# '''\n",
    "# backward function on score_max performs the backward pass in the computation graph and calculates the gradient of \n",
    "# score_max with respect to nodes in the computation graph\n",
    "# '''\n",
    "# score_max.backward()\n",
    "\n",
    "# '''\n",
    "# Saliency would be the gradient with respect to the input image now. But note that the input image has 3 channels,\n",
    "# R, G and B. To derive a single class saliency value for each pixel (i, j),  we take the maximum magnitude\n",
    "# across all colour channels.\n",
    "# '''\n",
    "# saliency, _ = torch.max(X.grad.data.abs(),dim=1)\n",
    "\n",
    "# # code to plot the saliency map as a heatmap\n",
    "# plt.imshow(saliency[0], cmap=plt.cm.hot)\n",
    "# plt.axis('off')\n",
    "# plt.show()\n",
    "# cv2.imwrite(\"output/t1.png\",(255*test[index][2][:,:,6:]).astype(\"int\"))\n",
    "# plt.imshow((255*test[index][2][:,:,6:]).astype(\"int\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
